{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 28801     \n",
      "=================================================================\n",
      "Total params: 269,633\n",
      "Trainable params: 269,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "base_dir = 'dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                    train_dir,\n",
    "                                    target_size=(150, 150),\n",
    "                                    batch_size=20,\n",
    "                                    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.6944 - acc: 0.5400\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6946 - acc: 0.5050\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6937 - acc: 0.4900\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6947 - acc: 0.4800\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6931 - acc: 0.5100\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['acc'])\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=10,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "img_path = 'cat.1566.jpg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00172897]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_output = model.output[:, 0]\n",
    "last_conv_layer = model.get_layer('conv2d_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "grads = K.gradients(cat_output, last_conv_layer.output)[0]\n",
    "pooled_grads =  K.mean(grads, axis=(0, 1, 2))\n",
    "iterate = K.function([model.input],[pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "for i in range(128):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20915f790f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-67ed22a557e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cat.1.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplyColorMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLORMAP_JET\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('cat.1.jpg')\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[1]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('cat_cam.png', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
